#!/usr/bin/env ruby

require "bundler/setup"
require "outboxer"
require "kafka"

cli_options = Outboxer::Publisher.parse_cli_options(ARGV)
environment = cli_options.delete(:environment) || ENV["APP_ENV"] || ENV["RAILS_ENV"] || "development"
options = Outboxer::Publisher::PUBLISH_MESSAGES_DEFAULTS.merge(cli_options)
logger = Outboxer::Logger.new($stdout, level: options[:log_level])

database_config = Outboxer::Database.config(
  environment: environment,
  pool: Outboxer::Publisher.pool(concurrency: options[:concurrency]))

Outboxer::Database.connect(config: database_config, logger: logger)

kafka = Kafka.new(
  seed_brokers: ENV.fetch("KAFKA_BROKERS").split(","), client_id: "outboxer")

producer = kafka.producer(required_acks: :all)

begin
  Outboxer::Publisher.publish_messages(batch_size: 100) do |publisher, messages|
    begin
      messages.each do |message|
        producer.produce(
          {
            messageable_type: message[:messageable_type],
            messageable_id: message[:messageable_id]
          }.to_json,
          topic: ENV.fetch("KAFKA_TOPIC"),
          key: message[:id].to_s)
      end

      producer.deliver_messages
    rescue => error
      logger.error(
        "Kafka::Producer#deliver_messages failed for publisher_id=#{publisher[:id]} " \
        "message_ids=#{messages.map { |message| message[:id] }.join(",")}\n" \
        "#{error.class}: #{error.message}\n" \
        "#{error.backtrace.join("\n")}")

      Outboxer::Publisher.update_messages_by_ids(
        publisher_id: publisher[:id],
        publisher_name: publisher[:name],
        failed_message_ids: messages.map { |message| message[:id] })
    else
      Outboxer::Publisher.update_messages_by_ids(
        publisher_id: publisher[:id],
        publisher_name: publisher[:name],
        published_message_ids: messages.map { |message| message[:id] })
    end
  end
ensure
  producer.shutdown

  Outboxer::Database.disconnect(logger: logger)
end
